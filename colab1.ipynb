{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a2e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.7 (v3.13.7:bcee1c32211, Aug 14 2025, 19:10:51) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "Executable: /usr/local/bin/python3.13\n",
      "Platform: macOS-15.1-arm64-arm-64bit-Mach-O\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Executable:\", sys.executable)\n",
    "print(\"Platform:\", platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c41c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch<3,>=2.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: transformers<5,>=4.44 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.57.1)\n",
      "Collecting datasets<3,>=2.20\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting accelerate<1,>=0.33\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.36.0)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch<3,>=2.3) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch<3,>=2.3) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch<3,>=2.3) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch<3,>=2.3) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch<3,>=2.3) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch<3,>=2.3) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch<3,>=2.3) (2025.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5,>=4.44) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets<3,>=2.20) (22.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets<3,>=2.20)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets<3,>=2.20) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets<3,>=2.20) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets<3,>=2.20) (0.70.18)\n",
      "Collecting fsspec>=0.8.5 (from torch<3,>=2.3)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets<3,>=2.20) (3.12.15)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from accelerate<1,>=0.33) (7.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets<3,>=2.20) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets<3,>=2.20) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets<3,>=2.20) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets<3,>=2.20) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets<3,>=2.20) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets<3,>=2.20) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp->datasets<3,>=2.20) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets<3,>=2.20) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers<5,>=4.44) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers<5,>=4.44) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers<5,>=4.44) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch<3,>=2.3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch<3,>=2.3) (3.0.2)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets<3,>=2.20)\n",
      "  Downloading multiprocess-0.70.17-py313-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets<3,>=2.20) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets<3,>=2.20) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets<3,>=2.20) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets<3,>=2.20) (1.17.0)\n",
      "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Installing collected packages: fsspec, dill, multiprocess, accelerate, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.9.0\n",
      "\u001b[2K    Uninstalling fsspec-2025.9.0:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.9.0\n",
      "\u001b[2K  Attempting uninstall: dill\n",
      "\u001b[2K    Found existing installation: dill 0.4.0\n",
      "\u001b[2K    Uninstalling dill-0.4.0:\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.0\n",
      "\u001b[2K  Attempting uninstall: multiprocess\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18\n",
      "\u001b[2K  Attempting uninstall: accelerate\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K    Found existing installation: accelerate 1.11.0━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling accelerate-1.11.0:[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.11.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K  Attempting uninstall: datasets0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K    Found existing installation: datasets 4.4.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling datasets-4.4.1:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.4.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [multiprocess]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [datasets]4/5\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.68.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.68.0 requires pyarrow<19.0.0,>=3.0.0, but you have pyarrow 22.0.0 which is incompatible.\n",
      "trl 0.25.0 requires accelerate>=1.4.0, but you have accelerate 0.34.2 which is incompatible.\n",
      "trl 0.25.0 requires datasets>=3.0.0, but you have datasets 2.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.34.2 datasets-2.21.0 dill-0.3.8 fsspec-2024.6.1 multiprocess-0.70.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"torch>=2.3,<3\" \"transformers>=4.44,<5\" \"datasets>=2.20,<3\" \"accelerate>=0.33,<1\" huggingface_hub sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5e236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps | dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "### Step 3:\n",
    "import os, torch\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"  # avoid hf_transfer requirement\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device_map = {\"\": \"mps\"}; dtype = torch.float16; dev = \"mps\"\n",
    "else:\n",
    "    device_map = {\"\": \"cpu\"}; dtype = torch.float32; dev = \"cpu\"\n",
    "\n",
    "print(\"Device:\", dev, \"| dtype:\", dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1014ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c1bd6d51bd4673b236e9556e096f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af29c61216664a5abba304f7b1ccf633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82d67a27ef149aca168c69a58819558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Step 4: Download the model snapshot\n",
    "MODEL_ID  = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "CACHE_DIR = \"./_hf_cache_smol\"\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "local_model_path = snapshot_download(\n",
    "    repo_id=MODEL_ID,\n",
    "    local_dir=CACHE_DIR,\n",
    "    allow_patterns=[\"*.safetensors\",\"*.bin\",\"*.json\",\"*.model\",\"tokenizer*\",\"*merges*\"],\n",
    "    resume_download=True,\n",
    "    max_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b8c9cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(49152, 576)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Step 5: Load tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    torch_dtype=dtype,          # fp16 on MPS, fp32 on CPU\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=device_map,\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8261bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "\n",
    "# tiny stop: cut if model starts a new turn marker\n",
    "class StopOnMarkers(StoppingCriteria):\n",
    "    def __init__(self, markers, tokenizer):\n",
    "        self.markers = markers\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs):\n",
    "        text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        return any(m in text for m in self.markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e0767af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_complete(prompt: str) -> str:\n",
    "    # Use tags the base model hasn't memorized as a dialogue format\n",
    "    text = f\"Instruction: {prompt}\\nAnswer:\"\n",
    "    enc = tokenizer(text, return_tensors=\"pt\")\n",
    "    dev = next(model.parameters()).device\n",
    "    enc = {k: v.to(dev) for k, v in enc.items()}\n",
    "\n",
    "    # Block common turn/openers the model drifts into\n",
    "    bad_phrases = [\"\\nQ:\", \"\\nA:\", \"\\nB:\", \"\\nB)\", \"\\nC:\", \"\\nC)\", \"Q:\", \"B:\", \"B)\", \"C:\", \"C)\"]\n",
    "    bad_words_ids = [tokenizer.encode(p, add_special_tokens=False) for p in bad_phrases if p.strip()]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=16,          # tight to avoid rambling\n",
    "            do_sample=False,            # greedy for stability\n",
    "            use_cache=True,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            bad_words_ids=bad_words_ids,\n",
    "        )\n",
    "\n",
    "    dec = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    ans = dec.split(\"Answer:\", 1)[-1]          # keep only after \"Answer:\"\n",
    "    ans = ans.split(\"\\n\", 1)[0].strip()        # cut at first newline\n",
    "    # keep a single short sentence at most\n",
    "    import re\n",
    "    m = re.search(r'(.+?[.!?])(\\s|$)', ans)\n",
    "    return (m.group(1).strip() if m else ans.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddb910f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello → I am a student.\n",
      "math  → 4\n"
     ]
    }
   ],
   "source": [
    "print(\"hello →\", qa_complete(\"Say hello in one short sentence.\"))\n",
    "print(\"math  →\", qa_complete(\"what's 2 times 2?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3630111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clear GPU memory\n",
    "import gc, torch\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
